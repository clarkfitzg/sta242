# Stats 242 Revised Project Proposal

## EDA and visualization of medium data sets using Python

Zhewen Hu and Clark Fitzgerald

(3rd group member dropped the class)

This project will focus on visualizing data sets containing between 10 thousand and 100 million
data points. It is too many data points for most conventional EDA plots, and yet it
still fits easily in memory. 
There are two main challenges with data
sets of this size- the time needed to plot, and overplotting.

The Bokeh project is actively developing this set of capabilities within
Python. Downsampling in particular is under active development.
By downsampling we can use fewer data points to achieve the same effect as a
plot with more data. We will determine if this works on a local machine as
well as on a server.

In this project we plan to push the limits of what Bokeh can do.
We'll start with some statistical simulations of data up to the limits of
memory.
For a more advanced application we will examine real data such as climate data collected by 
[NASA](http://disc.sci.gsfc.nasa.gov/daac-bin/DataHoldingsPDISC.pl?LOOKUPID_List=GPM_1AGMI). 
This data consists of several GB of data collected daily and stored in HDF5
format. It's made publicly available through an FTP server.

The focus will be on rapid exploratory data analysis at scale.
More precisely, when given an in memory data set with more than 10,000 data points
we'd like to create informative plots using just a laptop in under 2
seconds.

As time allows, we will pursue the following more ambitious tasks:

- Plotting maps using the climate data
- Animation and Interactivity on the climate data
- Rapid visualization of data on disk

## Learning objectives

There are two main aspects of data visualization: knowing what to plot, and
knowing how to do it. In this project we hope to enhance our skills and
experience in both aspects. The technologies we'll be working with are
Python, Bokeh, XML, and HDF5.
